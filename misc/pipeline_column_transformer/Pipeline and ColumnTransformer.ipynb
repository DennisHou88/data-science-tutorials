{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline and ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This notebook uses features introduced in Python 3.6 and sklearn 0.20.\n",
    "\n",
    "\n",
    "First we'll need a few imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obviously\n",
    "import pandas as pd\n",
    "\n",
    "# Some sklearn tools for preprocessing and building a pipeline. \n",
    "# ColumnTransformer was introduced in 0.20 so make sure you have this version\n",
    "\n",
    "# To build our pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Other helpers\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset can be downloaded [here](https://archive.ics.uci.edu/ml/datasets/bank+marketing). It consists of data from marketing campaigns of a Portuguese bank. We will try to build classifiers that can predict whether or not the client targeted by the campaign ended up subscribing to a term deposit (column `y`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     36548\n",
       "yes     4640\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/bank-additional-full.csv\", sep=\";\")\n",
    "df.y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is imbalanced, we will need to keep that in mind when building our models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get X, y\n",
    "y = df[\"y\"].map({\"no\":0, \"yes\":1})\n",
    "X = df.drop(\"y\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the features in the X matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. age (numeric)\n",
    "2. job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "3. marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "4. education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "5. default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "6. housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "7. loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "8. contact: contact communication type (categorical: 'cellular','telephone') \n",
    "9. month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "10. day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "11. duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "12. campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "13. pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "14. previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "15. poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "16. emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "17. cons.price.idx: consumer price index - monthly indicator (numeric) \n",
    "18. cons.conf.idx: consumer confidence index - monthly indicator (numeric) \n",
    "19. euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "20. nr.employed: number of employees - quarterly indicator (numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the comment about `duration` feature. We will exclude it from our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                 int64\n",
       "job                object\n",
       "marital            object\n",
       "education          object\n",
       "default            object\n",
       "housing            object\n",
       "loan               object\n",
       "contact            object\n",
       "month              object\n",
       "day_of_week        object\n",
       "campaign            int64\n",
       "pdays               int64\n",
       "previous            int64\n",
       "poutcome           object\n",
       "emp.var.rate      float64\n",
       "cons.price.idx    float64\n",
       "cons.conf.idx     float64\n",
       "euribor3m         float64\n",
       "nr.employed       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.drop(\"duration\", inplace=True, axis=1)\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a list of categorical and numerical features\n",
    "\n",
    "# Some such as default would be binary features, but since\n",
    "# they have a third class \"unknown\" we'll process them as non binary categorical\n",
    "num_features = [\"age\", \"campaign\", \"pdays\", \"previous\", \"emp.var.rate\", \n",
    "                \"cons.price.idx\", \"cons.conf.idx\",\"euribor3m\", \"nr.employed\"]\n",
    "\n",
    "cat_features = [\"job\", \"marital\", \"education\",\"default\", \"housing\", \"loan\",\n",
    "                \"contact\", \"month\", \"day_of_week\", \"poutcome\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create our \"pipeline\" models with `ColumnTransformer` and `Pipeline`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a new `ColumnTransformer` object that keeps our numerical features and apply one hot encoding on our categorical features. \n",
    "\n",
    "That will allow us to create a clean pipeline that includes both features engineering (one hot encoding here) and training the model (a nice way to avoid data leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new object in charge of preprocessing the data\n",
    "preprocessor = ColumnTransformer([(\"numerical\", \"passthrough\", num_features), \n",
    "                                  (\"categorical\", OneHotEncoder(sparse=False, \n",
    "                                                                handle_unknown=\"ignore\"),\n",
    "                                   cat_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define our 4 models as sklearn `Pipeline` objects, containing our preprocessing step and training of one given algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = Pipeline([(\"preprocessor\", preprocessor), \n",
    "                     (\"model\", LogisticRegression(class_weight=\"balanced\", \n",
    "                                                  solver=\"liblinear\", \n",
    "                                                  random_state=42))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, \n",
    "                                                    test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're good to go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's fine tune our logistic regression and evaluate its performance. We can treat our pipeline object like a normal sklearn model and call `.fit` or `.predict` on it. We can also directly pass it to the `GridSearchCV` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('preprocessor', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('numerical', 'passthrough', ['age', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'...alty='l2', random_state=42,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'model__C': [1, 1.3, 1.5]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring='accuracy',\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(lr_model, {\"model__C\": [1, 1.3, 1.5]}, \n",
    "                  n_jobs=-1, cv=5, scoring=\"accuracy\")\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see our best parameters and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__C': 1.5}\n",
      "0.8275814227740973\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_params_)\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retrain our model on the whole training data with the best parameters. First we need to update the parameters inside our pipeline. We can use the `set_params` method for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('preprocessor', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('numerical', 'passthrough', ['age', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'...alty='l2', random_state=42,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.set_params(**gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run `get_params` to get the parameters of our model as a sanity check that we have properly updated the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('preprocessor',\n",
       "   ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "            transformer_weights=None,\n",
       "            transformers=[('numerical', 'passthrough', ['age', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']), ('categorical', OneHotEncoder(categorical_features=None, categories=None,\n",
       "          dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "          n_values=None, sparse=False), ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome'])])),\n",
       "  ('model', LogisticRegression(C=1.5, class_weight='balanced', dual=False,\n",
       "             fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "             multi_class='warn', n_jobs=None, penalty='l2', random_state=42,\n",
       "             solver='liblinear', tol=0.0001, verbose=0, warm_start=False))],\n",
       " 'preprocessor': ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "          transformer_weights=None,\n",
       "          transformers=[('numerical', 'passthrough', ['age', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']), ('categorical', OneHotEncoder(categorical_features=None, categories=None,\n",
       "        dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "        n_values=None, sparse=False), ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome'])]),\n",
       " 'model': LogisticRegression(C=1.5, class_weight='balanced', dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "           multi_class='warn', n_jobs=None, penalty='l2', random_state=42,\n",
       "           solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       " 'preprocessor__n_jobs': None,\n",
       " 'preprocessor__remainder': 'drop',\n",
       " 'preprocessor__sparse_threshold': 0.3,\n",
       " 'preprocessor__transformer_weights': None,\n",
       " 'preprocessor__transformers': [('numerical',\n",
       "   'passthrough',\n",
       "   ['age',\n",
       "    'campaign',\n",
       "    'pdays',\n",
       "    'previous',\n",
       "    'emp.var.rate',\n",
       "    'cons.price.idx',\n",
       "    'cons.conf.idx',\n",
       "    'euribor3m',\n",
       "    'nr.employed']),\n",
       "  ('categorical', OneHotEncoder(categorical_features=None, categories=None,\n",
       "          dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "          n_values=None, sparse=False), ['job',\n",
       "    'marital',\n",
       "    'education',\n",
       "    'default',\n",
       "    'housing',\n",
       "    'loan',\n",
       "    'contact',\n",
       "    'month',\n",
       "    'day_of_week',\n",
       "    'poutcome'])],\n",
       " 'preprocessor__numerical': 'passthrough',\n",
       " 'preprocessor__categorical': OneHotEncoder(categorical_features=None, categories=None,\n",
       "        dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "        n_values=None, sparse=False),\n",
       " 'preprocessor__categorical__categorical_features': None,\n",
       " 'preprocessor__categorical__categories': None,\n",
       " 'preprocessor__categorical__dtype': numpy.float64,\n",
       " 'preprocessor__categorical__handle_unknown': 'ignore',\n",
       " 'preprocessor__categorical__n_values': None,\n",
       " 'preprocessor__categorical__sparse': False,\n",
       " 'model__C': 1.5,\n",
       " 'model__class_weight': 'balanced',\n",
       " 'model__dual': False,\n",
       " 'model__fit_intercept': True,\n",
       " 'model__intercept_scaling': 1,\n",
       " 'model__max_iter': 100,\n",
       " 'model__multi_class': 'warn',\n",
       " 'model__n_jobs': None,\n",
       " 'model__penalty': 'l2',\n",
       " 'model__random_state': 42,\n",
       " 'model__solver': 'liblinear',\n",
       " 'model__tol': 0.0001,\n",
       " 'model__verbose': 0,\n",
       " 'model__warm_start': False}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.get_params(\"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit the model on the whole training set and calculate accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('preprocessor', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('numerical', 'passthrough', ['age', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'...alty='l2', random_state=42,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8323217609452133"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.86      0.90     10965\n",
      "           1       0.36      0.65      0.46      1392\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     12357\n",
      "   macro avg       0.66      0.75      0.68     12357\n",
      "weighted avg       0.88      0.83      0.85     12357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the pipeline creates a temporary DataFrame that contains the one hot encoded features. If you want to debug your pipeline, you can access intermediary stages at any time. For instance below we get the preprocessor, extract the stage for categorical features and get the categories it has learnt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = lr_model.named_steps[\"preprocessor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_categories = preprocessor.named_transformers_[\"categorical\"].categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a list with all those features so we can reuse it later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ohe_features = [f\"{col}__{val}\" for col, vals in zip(cat_features, ohe_categories) \n",
    "                                    for val in vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = num_features + new_ohe_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'campaign',\n",
       " 'pdays',\n",
       " 'previous',\n",
       " 'emp.var.rate',\n",
       " 'cons.price.idx',\n",
       " 'cons.conf.idx',\n",
       " 'euribor3m',\n",
       " 'nr.employed',\n",
       " 'job__admin.',\n",
       " 'job__blue-collar',\n",
       " 'job__entrepreneur',\n",
       " 'job__housemaid',\n",
       " 'job__management',\n",
       " 'job__retired',\n",
       " 'job__self-employed',\n",
       " 'job__services',\n",
       " 'job__student',\n",
       " 'job__technician',\n",
       " 'job__unemployed',\n",
       " 'job__unknown',\n",
       " 'marital__divorced',\n",
       " 'marital__married',\n",
       " 'marital__single',\n",
       " 'marital__unknown',\n",
       " 'education__basic.4y',\n",
       " 'education__basic.6y',\n",
       " 'education__basic.9y',\n",
       " 'education__high.school',\n",
       " 'education__illiterate',\n",
       " 'education__professional.course',\n",
       " 'education__university.degree',\n",
       " 'education__unknown',\n",
       " 'default__no',\n",
       " 'default__unknown',\n",
       " 'default__yes',\n",
       " 'housing__no',\n",
       " 'housing__unknown',\n",
       " 'housing__yes',\n",
       " 'loan__no',\n",
       " 'loan__unknown',\n",
       " 'loan__yes',\n",
       " 'contact__cellular',\n",
       " 'contact__telephone',\n",
       " 'month__apr',\n",
       " 'month__aug',\n",
       " 'month__dec',\n",
       " 'month__jul',\n",
       " 'month__jun',\n",
       " 'month__mar',\n",
       " 'month__may',\n",
       " 'month__nov',\n",
       " 'month__oct',\n",
       " 'month__sep',\n",
       " 'day_of_week__fri',\n",
       " 'day_of_week__mon',\n",
       " 'day_of_week__thu',\n",
       " 'day_of_week__tue',\n",
       " 'day_of_week__wed',\n",
       " 'poutcome__failure',\n",
       " 'poutcome__nonexistent',\n",
       " 'poutcome__success']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, so now we have a nice list of columns after processing. Let's visualise the data in a dataframe just for sanity check. For that we can also call methods directly on specificy stages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>job__admin.</th>\n",
       "      <th>...</th>\n",
       "      <th>month__oct</th>\n",
       "      <th>month__sep</th>\n",
       "      <th>day_of_week__fri</th>\n",
       "      <th>day_of_week__mon</th>\n",
       "      <th>day_of_week__thu</th>\n",
       "      <th>day_of_week__tue</th>\n",
       "      <th>day_of_week__wed</th>\n",
       "      <th>poutcome__failure</th>\n",
       "      <th>poutcome__nonexistent</th>\n",
       "      <th>poutcome__success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.860</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.858</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>1.244</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.961</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>1.266</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  campaign  pdays  previous  emp.var.rate  cons.price.idx  \\\n",
       "0  50.0       2.0  999.0       0.0           1.1          93.994   \n",
       "1  51.0       5.0  999.0       0.0           1.1          93.994   \n",
       "2  46.0       2.0  999.0       0.0          -1.8          92.893   \n",
       "3  46.0       1.0  999.0       0.0           1.4          94.465   \n",
       "4  25.0       5.0  999.0       0.0          -1.8          92.893   \n",
       "\n",
       "   cons.conf.idx  euribor3m  nr.employed  job__admin.        ...          \\\n",
       "0          -36.4      4.860       5191.0          0.0        ...           \n",
       "1          -36.4      4.858       5191.0          0.0        ...           \n",
       "2          -46.2      1.244       5099.1          0.0        ...           \n",
       "3          -41.8      4.961       5228.1          1.0        ...           \n",
       "4          -46.2      1.266       5099.1          0.0        ...           \n",
       "\n",
       "   month__oct  month__sep  day_of_week__fri  day_of_week__mon  \\\n",
       "0         0.0         0.0               0.0               0.0   \n",
       "1         0.0         0.0               0.0               1.0   \n",
       "2         0.0         0.0               0.0               1.0   \n",
       "3         0.0         0.0               0.0               1.0   \n",
       "4         0.0         0.0               0.0               0.0   \n",
       "\n",
       "   day_of_week__thu  day_of_week__tue  day_of_week__wed  poutcome__failure  \\\n",
       "0               1.0               0.0               0.0                0.0   \n",
       "1               0.0               0.0               0.0                0.0   \n",
       "2               0.0               0.0               0.0                0.0   \n",
       "3               0.0               0.0               0.0                0.0   \n",
       "4               1.0               0.0               0.0                0.0   \n",
       "\n",
       "   poutcome__nonexistent  poutcome__success  \n",
       "0                    1.0                0.0  \n",
       "1                    1.0                0.0  \n",
       "2                    1.0                0.0  \n",
       "3                    1.0                0.0  \n",
       "4                    1.0                0.0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(lr_model.named_steps[\"preprocessor\"].transform(X_train), \n",
    "             columns=all_features).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have trained our first model, we can easily do the same with our three others. Having the preprocessing steps in a pipeline makes the code cleaner and easier to read: here all code is related to training the model only, not tweaking the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = Pipeline([(\"preprocessor\", preprocessor), \n",
    "                     (\"model\", DecisionTreeClassifier(class_weight=\"balanced\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('preprocessor', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('numerical', 'passthrough', ['age', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'...      min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'model__max_depth': [3, 5, 7], 'model__min_samples_split': [2, 5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(dt_model, {\"model__max_depth\": [3, 5, 7], \n",
    "                             \"model__min_samples_split\": [2, 5]}, \n",
    "                  n_jobs=-1, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see our best parameters and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__max_depth': 5, 'model__min_samples_split': 5}\n",
      "0.8509937220353092\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_params_)\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('preprocessor', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('numerical', 'passthrough', ['age', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'...      min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model.set_params(**gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model.fit(X_train, y_train)\n",
    "y_pred = dt_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8553046856033018"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92     10965\n",
      "           1       0.41      0.62      0.49      1392\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     12357\n",
      "   macro avg       0.68      0.75      0.70     12357\n",
      "weighted avg       0.89      0.86      0.87     12357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest\n",
    "rf_model = Pipeline([(\"preprocessor\", preprocessor), \n",
    "                     (\"model\", RandomForestClassifier(class_weight=\"balanced\", \n",
    "                                                      n_estimators=100, n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('preprocessor', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('numerical', 'passthrough', ['age', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'...ators=100, n_jobs=-1, oob_score=False,\n",
       "            random_state=None, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'model__max_depth': [10, 15], 'model__min_samples_split': [5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(rf_model, {\"model__max_depth\": [10, 15], \n",
    "                             \"model__min_samples_split\": [5, 10]}, \n",
    "                  n_jobs=-1, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see our best parameters and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__max_depth': 15, 'model__min_samples_split': 5}\n",
      "0.8741979119697548\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_params_)\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('preprocessor', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('numerical', 'passthrough', ['age', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'...ators=100, n_jobs=-1, oob_score=False,\n",
       "            random_state=None, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.set_params(**gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8804726066197297"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     10965\n",
      "           1       0.47      0.58      0.52      1392\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     12357\n",
      "   macro avg       0.71      0.75      0.73     12357\n",
      "weighted avg       0.89      0.88      0.89     12357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train an XGB model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline can work with any class compatible with scikit-learn, here we are using it with the XGBClassifier from xgboost for instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = Pipeline([(\"preprocessor\", preprocessor), \n",
    "                      # Add a scale_pos_weight to make it balanced\n",
    "                      (\"model\", XGBClassifier(scale_pos_weight=(1 - y.mean()), \n",
    "                                              n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('preprocessor', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('numerical', 'passthrough', ['age', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'..._lambda=1,\n",
       "       scale_pos_weight=0.8873458288821987, seed=None, silent=True,\n",
       "       subsample=1))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'model__max_depth': [5, 10], 'model__min_child_weight': [5, 10], 'model__n_estimators': [25]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(xgb_model, {\"model__max_depth\": [5, 10],\n",
    "                              \"model__min_child_weight\": [5, 10],\n",
    "                              \"model__n_estimators\": [25]},\n",
    "                  n_jobs=-1, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see our best parameters and score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__max_depth': 5, 'model__min_child_weight': 5, 'model__n_estimators': 25}\n",
      "0.9002115778155457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('preprocessor', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('numerical', 'passthrough', ['age', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'..._lambda=1,\n",
       "       scale_pos_weight=0.8873458288821987, seed=None, silent=True,\n",
       "       subsample=1))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gs.best_params_)\n",
    "print(gs.best_score_)\n",
    "xgb_model.set_params(**gs.best_params_)\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9014323865015781"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     10965\n",
      "           1       0.71      0.21      0.32      1392\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     12357\n",
      "   macro avg       0.81      0.60      0.64     12357\n",
      "weighted avg       0.89      0.90      0.88     12357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
